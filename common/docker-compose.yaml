version: '2.1'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.7.0
    container_name: elasticsearch
    environment:
      - node.name=elasticsearch
      - discovery.type=single-node
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - .es/:/usr/share/elasticsearch/data
    ports:
      - "9300:9300"
      - "9200:9200"
  kibana:
    image: docker.elastic.co/kibana/kibana:7.7.0
    container_name: kibana
    environment:
      ELASTICSEARCH_URL: "http://elasticsearch:9300"
    ports:
      - "5601:5601"
  logstash:
    image: docker.elastic.co/logstash/logstash:7.7.0
    container_name: logstash
    command: logstash -f /etc/logstash/conf.d/logstash.conf
    volumes:
      - ./config:/etc/logstash/conf.d
    ports:
      - "5000:5000"
#  grafana:
#    image: grafana/grafana:latest
#    ports:
#      - "3000:3000"
#    environment:
#      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
#      - GF_AUTH_ANONYMOUS_ENABLED=true
#      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
#    entrypoint:
#      - sh
#      - -euc
#      - |
#        mkdir -p /etc/grafana/provisioning/datasources
#        cat <<EOF > /etc/grafana/provisioning/datasources/ds.yaml
#        apiVersion: 1
#        datasources:
#        - name: Loki
#          type: loki
#          access: proxy
#          orgId: 1
#          url: http://loki:3100
#          basicAuth: false
#          isDefault: true
#          version: 1
#          editable: false
#        EOF
#        /run.sh
#  loki:
#    image: grafana/loki
#    ports:
#      - "3100:3100"
#    command: -config.file=/etc/loki/local-config.yaml
#    volumes:
#      - ./loki-data:/loki
  zipkin:
    image: 'openzipkin/zipkin:latest'
    ports:
      - '9411:9411'
#  redis:
#    image: bitnami/redis
#    volumes:
#      - .redis/:/bitnami/redis/data
#    environment:
#      - ALLOW_EMPTY_PASSWORD=yes
#  kafdrop:
#    image: obsidiandynamics/kafdrop
#    restart: "always"
#    ports:
#      - "9000:9000"
#    environment:
#      KAFKA_BROKERCONNECT: "kafka:9092"
#    depends_on:
#      - "kafka"
#  kafka:
#    image: bitnami/kafka
#    ports:
#      - "9092:9092"
#      - "9094:9094"
#    volumes:
#      - .data/:/bitnami/kafka
#    environment:
#      # KRaft settings
#      - KAFKA_CFG_NODE_ID=0
#      - KAFKA_CFG_PROCESS_ROLES=controller,broker
#      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
#      # Listeners
#      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
#      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
#      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
#      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
#      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
  keycloak:
    image: quay.io/keycloak/keycloak
    command: ["start-dev"]
    restart: unless-stopped
    volumes:
      - ./keycloak:/opt/keycloak/data/
    environment:
      KC_METRICS_ENABLED: true
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
    ports:
      - "8090:8080"
  database:
    image: postgres:latest
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: "postgres"
      POSTGRES_PASSWORD: "postgres"
      POSTGRES_DB:       "ostock_dev"
    volumes:
      - ./init.sql:/docker-entrypoint-initdb.d/1-init.sql
      - ./data.sql:/docker-entrypoint-initdb.d/2-data.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
